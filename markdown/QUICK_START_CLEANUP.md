# Quick Start: Clean Your Vector Database

## ğŸš¨ Problems You're Experiencing
1. âŒ Corrupted vectors with garbled text (`ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½`)
2. âŒ PDFs and binary files incorrectly scraped
3. âŒ Poor quality RAG search results

## âœ… Quick Fix (2 Commands)

### 1. Remove Corrupted Text Vectors
```bash
python cleanup_corrupted_vectors.py
```
Type `yes` when prompted.

### 2. Remove PDF/Binary Vectors
```bash
python cleanup_pdf_vectors.py
```
Type `yes` when prompted.

## ğŸ‰ Prevention is Automatic!

Your code has been **automatically updated** with 3 layers of protection:

### âœ… Layer 1: Spider Content-Type Filtering
- Checks HTTP headers before downloading
- Only processes HTML pages
- Skips PDFs, images, documents

### âœ… Layer 2: Pipeline URL Validation
- Validates URLs before processing
- Drops PDF/binary file URLs
- Catches query param variations

### âœ… Layer 3: Text Quality Checks
- Validates content quality
- Detects encoding issues
- Filters corrupted text

## ğŸ“Š After Your Next Crawl

You'll see stats like:
```
Data Cleaning Pipeline: Processed 1000 items, dropped 45 items (4.5%)
```

## ğŸ“š Full Documentation

- **PDF Issues:** See `PDF_FILTERING_GUIDE.md`
- **Corruption Issues:** See `CLEANUP_GUIDE.md`

## ğŸš€ Ready to Crawl Again?

Your system is now protected. Future scrapes will automatically filter:
- âœ… PDFs and Word documents
- âœ… Images and media files
- âœ… Corrupted/garbled text
- âœ… Binary content

Just run your crawler as normal! ğŸ¯
